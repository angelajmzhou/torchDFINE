{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMaaAOoFOxOL"
   },
   "source": [
    "# DFINE Tutorial\n",
    "## Overview\n",
    "\n",
    "DFINE, which stands for **Dynamical Flexible Inference for Nonlinear Embeddings**, is a neural network model that is developed to enable flexible inference, whether causally, non-causally, or even in the presence of missing neural observations. To enable flexible inference, a model must achieve all the following operations simultaneously, without the need to retrain a new model or change the inference structure:\n",
    "\n",
    "1\\) Causal inference (filtering) <br>\n",
    "2\\) Non-causal inference (smoothing) <br>\n",
    "3\\) Account for missing observations, which can occur in wireless neural interfaces\n",
    "\n",
    "DFINE achieves flexible inference. Also, DFINE’s inference is recursive and thus computationally efficient. Flexible inference is essential for developing neurotechnology, such as brain-machine interfaces (BMIs).\n",
    "\n",
    "### Model Architecture\n",
    "To achieve flexible inference, DFINE separates the model into jointly trained manifold and dynamic latent factors such that nonlinearity is captured through the manifold factors and the dynamics can be modeled in tractable linear form on this nonlinear manifold. Also, as its training loss, DFINE can use the future-step-ahead neural prediction error because of its flexible inference capability that allows it to efficiently and recursively compute this loss during training.\n",
    "\n",
    "Specifically, we define the two sets of latent factors as follows: 1) Manifold latent factors ${a}_t \\in \\mathbb{R}^{n_a \\times 1}$ and 2) Dynamic latent factors ${x}_t \\in \\mathbb{R}^{n_x \\times 1}$.\n",
    "\n",
    "First, the dynamic latent factors evolve in time with a linear Gaussian model: $\\begin{equation}{x}_{t+1} = A{x}_t + {w}_t\\tag{1}\\end{equation}$ where $A \\in \\mathbb{R}^{n_x \\times n_x}$ is the state transition matrix and ${w}_t \\in \\mathbb{R}^{n_x \\times 1}$ is zero-mean Gaussian noise with covariance matrix $W \\in \\mathbb{R}^{n_x \\times n_x}$. The manifold latent factors ${a}_t$ are related to the dynamic latent factors ${x}_t$ as: $\\begin{equation}{a}_t = C{x}_t + {r}_t\\tag{2}\\end{equation}$ where $C \\in \\mathbb{R}^{n_a \\times n_x}$ is the emission matrix and ${r}_t \\times \\mathbb{R}^{n_a \\times 1}$ is white Gaussian noise with covariance matrix $R \\in \\mathbb{R}^{n_a \\times n_a}$. Equations (1) and (2) form an LDM with learnable parameters $\\psi = \\{ A, C, W, R, {\\mu}_0, \\Lambda_0 \\}$ where ${\\mu}_0$ and $\\Lambda_0$ are the initial estimate and covariance of dynamic latent factors, respectively.\n",
    "\n",
    "Second, to model nonlinear mappings, we used MLP autoencoders to learn the mapping between neural observations ${y}_t$ and manifold latent factors ${a}_t$. We model the decoder part as a nonlinear mapping $f_\\theta(\\cdot)$ from manifold latent factors to neural observations: $\\begin{equation}{y}_t = f_\\theta({a}_t) + {v}_t\\tag{3}\\end{equation}$ where $\\theta$ are parameters and ${v}_t \\in \\mathbb{R}^{n_y \\times 1}$ is a white Gaussian noise with covariance $V \\in \\mathbb{R}^{n_y \\times n_y}$. Equations (1)-(3) together form the generative model.\n",
    "\n",
    "For inference, we also need the mapping from ${y}_t$ to ${a}_t$, which we characterize as: $\\begin{equation}{a}_t = f_\\phi ({y}_t)\\tag{4}\\end{equation}$ where $f_\\phi(\\cdot)$ represents the encoder in the autoencoder structure and is parameterized by another MLP. All equations above are trained together end-to-end, rather than separately. Further, the middle manifold layer in equation (2) explicitly incorporates a\n",
    "stochastic noise variable $r_t$, whose covariance is learned during training, allowing the nonlinearity with respect to the dynamic latent factors to be stochastic in DFINE. To help with robustness to noise and stochasticity during inference, DFINE learns all the stochastic noise distribution parameters during training, which are then explicitly accounted for at inference.\n",
    "\n",
    "\n",
    "### The Inference Problem\n",
    "Using the equations above, we can infer both the manifold and dynamic latent factors from neural observations ${y}_{1:T}$, where $T$ is the total number of time steps for the observations. We use subscript $t|k$ to denote the inferred latent factors at time $t$ given observations up to time $k$, ${y}_{1:k}$. Thus, $t|t$ denotes filtering (causal) inference given ${y}_{1:t}$, $t+k|t$ denotes the $k$-step-ahead prediction given $y_{1:t}$, and $t|T$ denotes smoothing (non-causal) inference given ${y}_{1:T}$.\n",
    "\n",
    "The inference method is shown in Figure 1b in the paper and is as follows. We first directly but statically obtain an initial estimate of ${a}_t$ based on ${y}_t$ with ${\\hat{a}}_t = f_\\phi({y}_t)$ in equation (4), to provide the noisy observations of the dynamical model, that is, ${\\hat{a}}_t$. Having obtained ${\\hat{a}}_t$, we can now use the dynamical part of the model in equations (1) and (2) to infer ${x}_{t|t}$ with Kalman filtering from ${\\hat{a}}_{1:t}$, and infer ${x}_{t|T}$ with Kalman smoothing from ${\\hat{a}}_{1∶T}$. We can then infer the manifold latent factor as ${a}_{t|t} = C{x}_{t|t}$ and ${a}_{t|T} = C{x}_{t|T}$ on the basis of equation (2). Similarly, we can obtain the filtered neural activity ${y}_{t|t}$ and smoothed neural activity ${y}_{t|T}$ using equation (3) as ${y}_{t|t} = f_{\\theta}({a}_{t|t})$ and ${y}_{t|T} = f_{\\theta}({a}_{t|T})$, respectively.\n",
    "\n",
    "To obtain the $k$-step-ahead predicted neural activity ${y}_{t+k|t}$, we first recursively forward predict the dynamic latent factors $k$ time-steps with the Kalman predictor, and obtain ${x}_{t+k|t}$. Then, we can compute the $k$-step-ahead predictions of manifold latent factors and neural observations with ${a}_{t+k|t} = C{x}_{t+k|t}$ and ${y}_{t+k|t} = f_{\\theta}({a}_{t+k|t})$, respectively.\n",
    "\n",
    "### Training Loss Function\n",
    "Having established the DFINE model and its inference, we can learn the model parameters $\\psi, \\theta, \\phi$ by minimizing:  $\\begin{equation}L(\\psi, \\theta, \\phi) = \\sum_{k=1}^K \\sum_{t=1}^{T-k} e({y}_{t+k|t}, {y}_{t+k}) + \\lambda_{reg} L_2 (\\theta, \\phi)\\tag{5}\\end{equation}$ where $K$ denotes the maximum horizon for future-step-ahead prediction, $e(\\cdot, \\cdot)$ denotes the error measure which is taken as mean-squared error (MSE) loss, $L_2(\\cdot)$ is L2 regularization for the autoencoder parameters $\\{\\theta, \\phi\\}$ to prevent overfitting, and $\\lambda_{reg}$ is the L2 regularization loss scale (see config_dfine.py).\n",
    "\n",
    "### Training tips and hyperparameters\n",
    "DFINE does not have many hyperparameters to tune. Yet **it may be necessary to search over a grid of the following hyperparameters to find the best performing ones for a given dataset (especially for L2 regularization loss scale)**:\n",
    "- L2 regularization loss scale, config.loss.scale_l2. For hyperparameter search, you can use a small grid such as [1e-4, 5e-4, 1e-3, 2e-3] after z-scoring the signals (see below).\n",
    "- $K$, future-step-ahead prediction horizon provided as a list, config.loss.steps_ahead\n",
    "- Encoder/decoder architecture, i.e., number of hidden layers and units in each layer, config.model.hidden_layer_list\n",
    "- Setting $n_a$ higher than $n_y$ may lead to overfitting, it's recommended that $n_a \\leq n_y$\n",
    "- As we show in Extended Data Fig. 8, it's recommended to set $n_a = n_x$ to reduce the hyperparameter search complexity\n",
    "\n",
    "For default values of all hyperparameters, please see config_dfine.py. For the future-step-ahead prediction horizon, we used $K=4$, or config.loss.steps_ahead = [1,2,3,4] for DFINE.\n",
    "\n",
    "It is important to note that for neural signals, we performed **z-scoring** which is highly recommended, please see below and time_series_utils.z_score_tensor. Recommendations above for L2 regularization scale are with z-scoring, which can affect the choice of L2 regularization scale.\n",
    "\n",
    "\n",
    "**DFINE is currently implemented for continuous-valued signals**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\DFINE_env\\lib\\site-packages\\torchaudio\\backend\\utils.py:66: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from itertools import product\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from config_dfine import get_default_config\n",
    "from trainers.TrainerDFINE import TrainerDFINE\n",
    "from datasets import DFINEDataset\n",
    "from time_series_utils import z_score_tensor, get_nrmse_error\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def train_test_split(y, train_ratio, batch_size = 4, shuffleTrain = True):\n",
    "# Split data into training and test datasets\n",
    "    num_trials = y.shape[0]\n",
    "    num_train_trials = int(train_ratio * num_trials)\n",
    "    num_test_trials = num_trials - num_train_trials\n",
    "    train_y = y[:num_train_trials, ...]\n",
    "    test_y = y[num_train_trials:, ...]\n",
    "\n",
    "    # Z-score the observation tensors\n",
    "    train_y_zsc, mean_y, std_y = z_score_tensor(train_y, fit=True)\n",
    "    test_y_zsc, _, _ = z_score_tensor(test_y, mean=mean_y, std=std_y, fit=False)\n",
    "\n",
    "    # Create DFINE dataset objects and torch dataloaders\n",
    "    train_dataset = DFINEDataset(y=train_y_zsc)\n",
    "    test_dataset = DFINEDataset(y=test_y_zsc)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle= shuffleTrain)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_dataset, test_dataset, train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"scale_l2\": [0.0001, 0.001],\n",
    "    \"latent_factors\" :[7,15]\n",
    "}\n",
    "\n",
    "param_combinations = list(product(*param_grid.values()))\n",
    "param_names = list(param_grid.keys())\n",
    "\n",
    "# Store the best configuration\n",
    "best_params = None\n",
    "best_score = float(\"inf\")\n",
    "\n",
    "\n",
    "for subj in range(1, 21):\n",
    "    subj_num = f\"{subj:02}\" \n",
    "    f = h5py.File('GTH_data\\GTH_s' + str(subj_num) + '_decision_power_struct_nobs.mat', 'r')\n",
    "    dataset = list(f[\"power_struct\"][\"highgamma\"][\"powspctrm\"])\n",
    "    labelsset = np.array(f[\"power_struct\"][\"beh\"][\"gambles\"])\n",
    "    \n",
    "    gen_data = f[\"power_struct\"][\"highgamma\"][\"powspctrm\"]\n",
    "    highgamma = np.array(gen_data) # (time, electrodes, trials)\n",
    "    y= np.moveaxis(highgamma,2,0) # (trials, time, channels)\n",
    "    print(\"dim are: \" , y.shape) #(num_seq, num_steps, dim_y)\n",
    "    seed=0\n",
    "    set_seed(seed)\n",
    "    for params in param_combinations:\n",
    "        # Map parameters to config\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "        latent_factors = param_dict[\"latent_factors\"]\n",
    "        scale_l2 = param_dict[\"scale_l2\"]\n",
    "        config = get_default_config()\n",
    "        config.device = 'cuda'\n",
    "        config.model.activation ='tanh'\n",
    "        config.train.num_epochs = 20\n",
    "        config.train.batch_size = 4\n",
    "        config.lr.init = 0.01\n",
    "        config.model.supervise_behv = False\n",
    "        config.seed = seed\n",
    "        config.model.dim_y = y.shape[2]    \n",
    "        config.model.dim_a = latent_factors     #manifold latent factors\n",
    "        config.model.dim_x = latent_factors     #dynamic latent factors (should be same as dim a)\n",
    "        config.loss.scale_l2 = scale_l2\n",
    "        config.model.save_dir = f'./results/neural/subj_{subj_num}_l2_{scale_l2}_nlatent_{latent_factors}'\n",
    "        trainer_load = TrainerDFINE(config=config)\n",
    "    \n",
    "    \n",
    "        labelsset = labelsset.T\n",
    "        behv_mask = torch.tensor(labelsset)\n",
    "        behv_mask = behv_mask.squeeze() \n",
    "    \n",
    "        # Filter trials based on the mask\n",
    "        gamble = y[behv_mask == 1]  # Trials where the mask is 1\n",
    "        no_gamble = y[behv_mask == 0]  # Trials where the mask is 0\n",
    "    \n",
    "        # Output shapes\n",
    "        print(\"Gamble shape:\", gamble.shape)  # (num_seq_1, 5000, 32)\n",
    "        print(\"No Gamble shape:\", no_gamble.shape)  # (num_seq_0, 5000, 32)\n",
    "    \n",
    "        train_dataset, test_dataset, train_loader, test_loader = train_test_split(y, 0.8)\n",
    "    \n",
    "        trainer_load.train(train_loader=train_loader, valid_loader=test_loader)\n",
    "    #CONTINUE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def avg_latent_factor_plot(f, savedir, prefix='gamble', feat_name='x_smooth'):\n",
    "        '''\n",
    "        Creates dynamic latent factor plots during training/validation\n",
    "\n",
    "        Parameters:\n",
    "        ------------\n",
    "        - f: torch.Tensor, shape: (num_seq, num_steps, dim_x/dim_a), Batch of inferred dynamic/manifold latent factors, smoothed/filtered factors can be provided\n",
    "        - epoch: int, Number of epoch for which to create dynamic latent factor plot\n",
    "        - trial_num: int, Trial number to plot\n",
    "        - prefix: str, Plotname prefix to save plots\n",
    "        - feat_name: str, Feature name of y_hat_batch (e.g. y_hat/y_smooth) used in plotname\n",
    "        '''\n",
    "        \n",
    "        # From feat_name, get whether it's manifold or dynamic latent factors\n",
    "        if feat_name[0].lower() == 'x':\n",
    "            feat_name = 'Dynamic'\n",
    "        else:\n",
    "            feat_name = 'Manifold' \n",
    "\n",
    "        # Create the figure and colormap\n",
    "        fig = plt.figure(figsize=(10,8))\n",
    "        num_steps, dim_f = f.shape\n",
    "        color_index = range(num_steps)\n",
    "        color_map = plt.cm.get_cmap('viridis')\n",
    "        \n",
    "        if dim_f > 2:\n",
    "            # Scatter first 3 dimensions of dynamic latent factors \n",
    "            ax = fig.add_subplot(221, projection='3d')\n",
    "            ax_m = ax.scatter(f[:, 0], f[:, 1], f[:, 2], c=color_index, vmin=0, vmax=num_steps, s=35, cmap=color_map)\n",
    "            ax.set_xlabel('Dim 0')\n",
    "            ax.set_ylabel('Dim 1')\n",
    "            ax.set_zlabel('Dim 2')\n",
    "            ax.set_title(f'{feat_name} latent factors in 3D')\n",
    "            fig.colorbar(ax_m)\n",
    "\n",
    "            # Scatter first 2 dimensions of dynamic latent factors, top view\n",
    "            ax = fig.add_subplot(222)\n",
    "            ax_m = ax.scatter(f[:, 0], f[:, 1], c=color_index, vmin=0, vmax=num_steps, s=35, cmap=color_map)\n",
    "            ax.set_xlabel('Dim 0')\n",
    "            ax.set_ylabel('Dim 1')\n",
    "            ax.set_title(f'{feat_name} latent factors from top')\n",
    "            fig.colorbar(ax_m)\n",
    "\n",
    "            # Plot the first dimension of dynamic latent factors\n",
    "            ax = fig.add_subplot(223)\n",
    "            ax.plot(range(num_steps), f[:, 0])\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Dim 0')\n",
    "\n",
    "            # Plot the second dimension of dynamic latent factors\n",
    "            ax = fig.add_subplot(224)\n",
    "            ax.plot(range(num_steps), f[:, 1])\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Dim 1')\n",
    "\n",
    "        elif dim_f == 2:\n",
    "            # Scatter first 2 dimensions of dynamic latent factors, top view\n",
    "            ax = fig.add_subplot(221)\n",
    "            ax_m = ax.scatter(f[:, 0], f[:, 1], c=color_index, vmin=0, vmax=num_steps, s=35, cmap=color_map)\n",
    "            ax.set_xlabel('Dim 0')\n",
    "            ax.set_ylabel('Dim 1')\n",
    "            ax.set_title(f'{feat_name} latent factors from top')\n",
    "            fig.colorbar(ax_m)\n",
    "\n",
    "            # Plot the first dimension of dynamic latent factors\n",
    "            ax = fig.add_subplot(222)\n",
    "            ax.plot(range(num_steps), f[:, 0])\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Dim 0')\n",
    "\n",
    "            # Plot the second dimension of dynamic latent factors\n",
    "            ax = fig.add_subplot(223)\n",
    "            ax.plot(range(num_steps), f[:, 1])\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Dim 1')\n",
    "\n",
    "        else:\n",
    "            # Plot the first dimension of dynamic latent factors\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.plot(range(num_steps), f[:, 0])\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Dim 0')\n",
    "        fig.suptitle(f'{feat_name} latent factors info', fontsize=16)\n",
    "        \n",
    "        # Save the plot under plot_save_dir\n",
    "        plot_name = f'{prefix}_{feat_name}_avg.png'\n",
    "        plt.savefig(os.path.join(savedir, \"plots\", plot_name))\n",
    "        plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def findEuclidianDist(series1, series2):\n",
    "\n",
    "    # Compute Euclidean distances for each time step\n",
    "    distances = torch.sqrt(torch.sum((series1 - series2) ** 2, dim=1))  #sum over dimension tuples\n",
    "\n",
    "    # Overall distance (optional)\n",
    "    total_distance = distances.sum()  # Total distance\n",
    "    mean_distance = distances.mean()  # Total distance\n",
    "\n",
    "    return total_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim are:  (180, 5001, 57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/03/2025 01:10:59 AM - DFINE Logger - WARNING - Optimizer and LR scheduler can be loaded only in resume_train mode, else they are re-initialized\n",
      "02/03/2025 01:10:59 AM - DFINE Logger - INFO - Loading model from: ./results/neural/subj_01_l2_0.0001_nlatent_15\\ckpts\\best_loss_ckpt.pth...\n",
      "02/03/2025 01:10:59 AM - DFINE Logger - INFO - Checkpoint succesfully loaded from ./results/neural/subj_01_l2_0.0001_nlatent_15\\ckpts\\best_loss_ckpt.pth!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainerDFINE loaded from: C:\\Users\\angel\\Desktop\\Code\\torchDFINE\\trainers\\TrainerDFINE.py\n",
      "File does not exist.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m no_gamble_dataset,_, no_gamble_loader ,_ \u001b[38;5;241m=\u001b[39m train_test_split(no_gamble, \u001b[38;5;241m1\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     81\u001b[0m g_train_loader \u001b[38;5;241m=\u001b[39m DataLoader(gamble_dataset, batch_size \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 82\u001b[0m gamble_latents \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_latents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamble_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m no_train_loader \u001b[38;5;241m=\u001b[39m DataLoader(no_gamble_dataset, batch_size \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m1\u001b[39m, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[0;32m     85\u001b[0m no_gamble_latents \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcompute_latents(train_loader\u001b[38;5;241m=\u001b[39m no_gamble_loader)\n",
      "File \u001b[1;32m~\\Desktop\\Code\\torchDFINE\\trainers\\TrainerDFINE.py:928\u001b[0m, in \u001b[0;36mTrainerDFINE.compute_latents\u001b[1;34m(self, train_loader, valid_loader)\u001b[0m\n\u001b[0;32m    926\u001b[0m batch \u001b[38;5;241m=\u001b[39m carry_to_device(batch, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    927\u001b[0m y_batch, behv_batch, mask_batch \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m--> 928\u001b[0m model_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdfine\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;66;03m# Append results\u001b[39;00m\n\u001b[0;32m    932\u001b[0m encoding_dict[train_valid][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_pred\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(model_vars[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_pred\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\DFINE_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\Code\\torchDFINE\\DFINE.py:223\u001b[0m, in \u001b[0;36mDFINE.forward\u001b[1;34m(self, y, mask)\u001b[0m\n\u001b[0;32m    220\u001b[0m a_hat \u001b[38;5;241m=\u001b[39m a_hat\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_a)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Run LDM to infer filtered and smoothed dynamic latent factors\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m x_pred, x_filter, x_smooth, Lambda_pred, Lambda_filter, Lambda_smooth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mldm\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldm\u001b[38;5;241m.\u001b[39mA\u001b[38;5;241m.\u001b[39mrepeat(num_seq, num_steps, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    225\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldm\u001b[38;5;241m.\u001b[39mC\u001b[38;5;241m.\u001b[39mrepeat(num_seq, num_steps, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\DFINE_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\Code\\torchDFINE\\modules\\LDM.py:363\u001b[0m, in \u001b[0;36mLDM.forward\u001b[1;34m(self, a, mask, do_smoothing)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03mForward pass function for LDM Module\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m- Lambda_back_all: torch.Tensor, shape: (num_seq, num_steps, dim_x, dim_x), Dynamic latent factor estimation error covariance smoothed estimates (t|T) where first index of the second dimension has P_{0|T}. Ones tensor if do_smoothing is False\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_smoothing:\n\u001b[1;32m--> 363\u001b[0m     mu_pred_all, mu_t_all, mu_back_all, Lambda_pred_all, Lambda_t_all, Lambda_back_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooth\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    365\u001b[0m     mu_pred_all, mu_t_all, Lambda_pred_all, Lambda_t_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter(a\u001b[38;5;241m=\u001b[39ma, mask\u001b[38;5;241m=\u001b[39mmask)\n",
      "File \u001b[1;32m~\\Desktop\\Code\\torchDFINE\\modules\\LDM.py:323\u001b[0m, in \u001b[0;36mLDM.smooth\u001b[1;34m(self, a, mask)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msmooth\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    Performs Rauch-Tung-Striebel (RTS) Smoothing\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m    - Lambda_back_all: torch.Tensor, shape: (num_seq, num_steps, dim_x, dim_x), Dynamic latent factor estimation error covariance smoothed estimates (t|T) where first index of the second dimension has P_{0|T}\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 323\u001b[0m     mu_pred_all, mu_t_all, Lambda_pred_all, Lambda_t_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_forwards\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m     mu_back_all, Lambda_back_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_backwards(mu_pred_all\u001b[38;5;241m=\u001b[39mmu_pred_all, \n\u001b[0;32m    325\u001b[0m                                                          mu_t_all\u001b[38;5;241m=\u001b[39mmu_t_all, \n\u001b[0;32m    326\u001b[0m                                                          Lambda_pred_all\u001b[38;5;241m=\u001b[39mLambda_pred_all, \n\u001b[0;32m    327\u001b[0m                                                          Lambda_t_all\u001b[38;5;241m=\u001b[39mLambda_t_all)\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;66;03m# Swab num_seq and num_steps dimensions\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Code\\torchDFINE\\modules\\LDM.py:202\u001b[0m, in \u001b[0;36mLDM.compute_forwards\u001b[1;34m(self, a, mask)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# Project system uncertainty into measurement space, get Kalman Gain\u001b[39;00m\n\u001b[0;32m    201\u001b[0m S \u001b[38;5;241m=\u001b[39m C_t \u001b[38;5;241m@\u001b[39m Lambda_pred \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mpermute(C_t, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m R \u001b[38;5;66;03m# num_seq, dim_a, dim_a)\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m S_inv \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# num_seq, dim_a, dim_a)\u001b[39;00m\n\u001b[0;32m    203\u001b[0m K \u001b[38;5;241m=\u001b[39m Lambda_pred \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mpermute(C_t, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m@\u001b[39m S_inv \u001b[38;5;66;03m# (num_seq, dim_x, dim_a)\u001b[39;00m\n\u001b[0;32m    204\u001b[0m K \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(K, mask[:, t, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# (num_seq, dim_x, dim_a) x (num_seq, 1,  1)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"scale_l2\": [0.0001, 0.001],\n",
    "    \"latent_factors\" :[15,30]\n",
    "}\n",
    "\n",
    "param_combinations = list(product(*param_grid.values()))\n",
    "param_names = list(param_grid.keys())\n",
    "\n",
    "# Store the best configuration\n",
    "best_params = None\n",
    "best_score = float(\"inf\")\n",
    "\n",
    "\n",
    "for subj in range(1, 21):\n",
    "    subj_num = f\"{subj:02}\" \n",
    "    f = h5py.File('GTH_data\\GTH_s' + str(subj_num) + '_decision_power_struct_nobs.mat', 'r')\n",
    "    dataset = list(f[\"power_struct\"][\"highgamma\"][\"powspctrm\"])\n",
    "    labelsset = np.array(f[\"power_struct\"][\"beh\"][\"gambles\"])\n",
    "    \n",
    "    gen_data = f[\"power_struct\"][\"highgamma\"][\"powspctrm\"]\n",
    "    highgamma = np.array(gen_data) # (time, electrodes, trials)\n",
    "    y= np.moveaxis(highgamma,2,0) # (trials, time, channels)\n",
    "    print(\"dim are: \" , y.shape) #(num_seq, num_steps, dim_y)\n",
    "\n",
    "    labelsset = labelsset.T\n",
    "    behv_mask = torch.tensor(labelsset)\n",
    "    behv_mask = behv_mask.squeeze() \n",
    "\n",
    "    gamble = y[behv_mask == 1]\n",
    "    no_gamble = y[behv_mask == 0] \n",
    "    seed=0\n",
    "    set_seed(seed)\n",
    "    for params in param_combinations:\n",
    "        # Map parameters to config\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "        latent_factors = param_dict[\"latent_factors\"]\n",
    "        scale_l2 = param_dict[\"scale_l2\"]\n",
    "        config = get_default_config()\n",
    "        config.device = 'cuda'\n",
    "        config.model.activation ='tanh'\n",
    "        config.train.num_epochs = 40\n",
    "        config.train.batch_size = 4\n",
    "        config.lr.init = 0.01\n",
    "        config.model.supervise_behv = False\n",
    "        config.seed = seed\n",
    "        config.model.dim_y = y.shape[2]    \n",
    "        config.model.dim_a = latent_factors     #manifold latent factors\n",
    "        config.model.dim_x = latent_factors     #dynamic latent factors (should be same as dim a)\n",
    "        config.loss.scale_l2 = scale_l2\n",
    "        config.model.save_dir = f'./results/neural/subj_{subj_num}_l2_{scale_l2}_nlatent_{latent_factors}'\n",
    "        \n",
    "        config.load.ckpt = 'best_loss'\n",
    "        trainer = TrainerDFINE(config=config)\n",
    "        \n",
    "        predictions = {\n",
    "            \"x_pred\": [],\n",
    "            \"x_filter\": [],\n",
    "            \"x_smooth\": [],\n",
    "            \"a_hat\": [],\n",
    "            \"a_pred\": [],\n",
    "            \"a_filter\": [],\n",
    "            \"a_smooth\": [],\n",
    "        }\n",
    "        \n",
    "        g_file_path = os.path.join(config.model.save_dir, 'g_latents.pt')\n",
    "        ng_file_path = os.path.join(config.model.save_dir, 'ng_latents.pt')\n",
    "        all_file_path = os.path.join(config.model.save_dir, 'batchwise_latents.pt')\n",
    "        if os.path.exists(g_file_path) and  os.path.exists(ng_file_path) and os.path.exists(all_file_path):\n",
    "            gamble_latents = torch.load(g_file_path)\n",
    "            no_gamble_latents = torch.load(ng_file_path)\n",
    "            all_latents = torch.load(all_file_path)\n",
    "            print(\"File loaded successfully.\")\n",
    "        else:\n",
    "            print(\"File does not exist.\")\n",
    "            gamble_dataset,  _,gamble_loader, _ = train_test_split(gamble, 1, batch_size = 1)\n",
    "            no_gamble_dataset,_, no_gamble_loader ,_ = train_test_split(no_gamble, 1, batch_size = 1)\n",
    "    \n",
    "            g_train_loader = DataLoader(gamble_dataset, batch_size =  1, shuffle= False)\n",
    "            gamble_latents = trainer.compute_latents(train_loader=gamble_loader)\n",
    "    \n",
    "            no_train_loader = DataLoader(no_gamble_dataset, batch_size =  1, shuffle = False) \n",
    "            no_gamble_latents = trainer.compute_latents(train_loader= no_gamble_loader)\n",
    "    \n",
    "            train_y_zsc, mean_y, std_y = z_score_tensor(y, fit=True)\n",
    "            train_dataset = DFINEDataset(y=train_y_zsc)\n",
    "            train_loader = DataLoader(train_dataset, batch_size = 1, shuffle=False)\n",
    "            all_latents = trainer.compute_latents(train_loader= train_loader)\n",
    "            torch.save(gamble_latents, g_file_path)\n",
    "            torch.save(no_gamble_latents, ng_file_path)\n",
    "            torch.save(all_latents, all_file_path)\n",
    "    \n",
    "        save_dir = os.path.join(config.model.save_dir, 'confusion_matrices')\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    \n",
    "        confusion_matrices = {}\n",
    "        num_g_trials = np.sum(labelsset)\n",
    "        num_ng_trials = y.shape[0]-num_g_trials\n",
    "        for key in gamble_latents['train'].keys():\n",
    "            if key == 'mask':\n",
    "                continue\n",
    "            total_g = torch.stack(gamble_latents['train'][key], dim=0).squeeze().sum(dim=0, keepdim = True).squeeze()[2000:3001]\n",
    "            total_ng = torch.stack(no_gamble_latents['train'][key], dim=0).squeeze().sum(dim=0, keepdim = True).squeeze()[2000:3001]\n",
    "    \n",
    "            avg_latent_factor_plot(total_g/num_g_trials, config.model.save_dir, feat_name=key)\n",
    "            avg_latent_factor_plot(total_ng/num_ng_trials, config.model.save_dir, prefix=\"no gamble\", feat_name=key)\n",
    "            for trial in range(0,y.shape[0]):\n",
    "                if labelsset[trial]:\n",
    "                    gamble_avg = ((total_g - all_latents['train'][key][trial].squeeze()[2000:3001]) / (num_g_trials-1))\n",
    "                    no_gamble_avg = total_ng/(num_ng_trials)\n",
    "                    \n",
    "                else:\n",
    "                    gamble_avg = total_g/(num_g_trials)\n",
    "                    no_gamble_avg = ((total_ng - all_latents['train'][key][trial].squeeze()[2000:3001]) /( num_ng_trials-1))\n",
    "    \n",
    "                test_data = all_latents['train'][key][trial].squeeze()[2000:3001]\n",
    "    \n",
    "                g_distances = findEuclidianDist(gamble_avg, test_data)\n",
    "                ng_distances =  findEuclidianDist(no_gamble_avg, test_data)\n",
    "    \n",
    "                predictions[key].append(1 if ng_distances > g_distances else 0)\n",
    "    \n",
    "            cm = confusion_matrix(labelsset, predictions[key])\n",
    "        save_path = os.path.join(config.model.save_dir, f'{key}_eval_results.json')\n",
    "\n",
    "        if os.path.exists(save_path):\n",
    "            with open(save_path, \"r\") as json_file:\n",
    "                eval_results = json.load(json_file)\n",
    "                accuracy = eval_results['accuracy']\n",
    "                precision = eval_results['precision']\n",
    "                recall = eval_results['recall']\n",
    "                F1 = eval_results['F1_score']\n",
    "                model_loss = eval_results['model_loss']\n",
    "            \n",
    "        else:\n",
    "            print(\"File does not exist.\")\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            accuracy = (tn + tp) / np.sum(cm) \n",
    "            precision = tp / (tp + fp) \n",
    "            recall = tp / (tp + fn)\n",
    "            F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "            train_dataset, test_dataset, train_loader, test_loader = train_test_split(y, 0.8)\n",
    "            total_loss, loss_dict = trainer.model_eval(test_loader)\n",
    "            model_loss = loss_dict['model_loss'].item()\n",
    "            \n",
    "            eval_results = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"F1_score\": F1,\n",
    "                \"model_loss\": model_loss\n",
    "            }\n",
    "            \n",
    "            # Ensure directory exists and save JSON\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            \n",
    "            with open(save_path, \"w\") as json_file:\n",
    "                json.dump(eval_results, json_file, indent=4)\n",
    "                \n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Gamble\", \"Gamble\"])\n",
    "        disp.plot(cmap=\"Blues\")\n",
    "        plt.title(f\"Confusion Matrix for {key}\")\n",
    "        plt.text(1.7, 1.75, f'F1 score: {F1} \\n Accuracy: {accuracy} \\n Precision: {precision} \\n Recall: {recall} \\n model loss: {model_loss}', fontsize=5)\n",
    "        plt.savefig(os.path.join(save_dir, f\"{key}_confusion_matrix.png\"))\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
